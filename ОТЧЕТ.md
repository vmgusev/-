# ОТЧЕТ

## О самостоятельной практической работе
### «Классификация текстов на естественном языке с помощью машинного обучения»

---

## СОДЕРЖАНИЕ

1. [Введение](#введение)
2. [Постановка задачи](#постановка-задачи)
3. [Методы и инструменты](#методы-и-инструменты)
4. [Реализация](#реализация)
5. [Результаты](#результаты)
6. [Выводы](#выводы)
7. [Список использованных источников](#список-использованных-источников)

---

## ВВЕДЕНИЕ

Классификация текстов на естественном языке является одной из фундаментальных задач обработки естественного языка (Natural Language Processing, NLP). Эта задача находит широкое применение в различных областях: анализ тональности отзывов, категоризация новостей, фильтрация спама, определение авторства текстов и т.д.

В данной работе была реализована программа для классификации текстовых данных на русском языке с использованием различных подходов к векторизации текста и нескольких алгоритмов машинного обучения. Цель работы — сравнить эффективность частотного и семантического подходов к представлению текстов, а также различных алгоритмов классификации на задаче классификации отзывов о медицинских учреждениях по 5-балльной шкале (от 1 — негативный до 5 — позитивный отзыв).

---

## ПОСТАНОВКА ЗАДАЧИ

### Основные задачи работы:

1. **Разработка системы предобработки текстов:**
   - Очистка текстов от лишних символов
   - Лемматизация слов (приведение к нормальной форме)

2. **Реализация различных подходов к векторизации:**
   - Частотный подход (TF-IDF)
   - Семантический подход (Word2Vec)

3. **Обучение и сравнение алгоритмов классификации:**
   - Логистическая регрессия
   - Случайный лес (Random Forest)
   - Наивный байесовский классификатор (Naive Bayes)

4. **Оценка и визуализация результатов:**
   - Расчет метрик качества (accuracy, precision, recall, F1-score)
   - Сравнительный анализ результатов
   - Построение графиков сравнения

### Технические требования:

- Работа с текстами на русском языке
- Использование датасета на русском языке (из библиотеки Hugging Face или самостоятельно созданного)
- Обязательное использование лемматизации
- Сравнение минимум двух подходов к векторизации
- Сравнение минимум трех алгоритмов классификации

---

## МЕТОДЫ И ИНСТРУМЕНТЫ

### Используемые библиотеки и инструменты:

1. **Python 3.13.1** — язык программирования
2. **NumPy** — работа с массивами и математическими операциями
3. **Pandas** — обработка и анализ данных
4. **scikit-learn** — библиотека машинного обучения:
   - `TfidfVectorizer` — векторизация TF-IDF
   - `LogisticRegression` — логистическая регрессия
   - `RandomForestClassifier` — случайный лес
   - `MultinomialNB` — наивный байесовский классификатор
   - Метрики качества (`accuracy_score`, `classification_report`)
5. **pymorphy3** — морфологический анализ и лемматизация русского языка
6. **Gensim** — библиотека для работы с тематическим моделированием:
   - `Word2Vec` — семантическая векторизация
7. **datasets (Hugging Face)** — загрузка датасетов
8. **Matplotlib и Seaborn** — визуализация результатов

### Методы векторизации текстов:

#### 1. TF-IDF (Term Frequency-Inverse Document Frequency)

**Частотный подход** — метод, который оценивает важность слова в документе на основе частоты его встречаемости и обратной частоты документа в корпусе.

**Формула:**
```
TF-IDF(t, d) = TF(t, d) × IDF(t)

где:
TF(t, d) = количество вхождений термина t в документ d / общее количество терминов в d
IDF(t) = log(общее количество документов / количество документов, содержащих t)
```

**Преимущества:**
- Учитывает важность слов относительно корпуса
- Простота реализации и интерпретации
- Хорошо работает для задач классификации

**Параметры использованного векторизатора:**
- `max_features=3000` — максимальное количество признаков
- `ngram_range=(1, 2)` — использование униграмм и биграмм
- `min_df=2` — минимальная частота документа
- `max_df=0.95` — максимальная частота документа

#### 2. Word2Vec

**Семантический подход** — метод распределенного представления слов, который обучает векторные представления слов на основе контекста их употребления.

**Алгоритм:**
- Используется CBOW (Continuous Bag of Words) модель
- Создает плотные векторы фиксированной размерности (100)
- Вектор документа вычисляется как среднее арифметическое векторов всех слов в документе

**Преимущества:**
- Учитывает семантические связи между словами
- Создает более компактные представления
- Может улавливать смысловые отношения

**Параметры модели:**
- `vector_size=100` — размерность векторов
- `window=5` — размер окна контекста
- `min_count=2` — минимальная частота слова
- `sg=0` — использование CBOW (0) вместо Skip-gram (1)

### Алгоритмы классификации:

#### 1. Логистическая регрессия

Линейный алгоритм классификации, который использует логистическую функцию для моделирования вероятности принадлежности к классу.

**Преимущества:**
- Высокая интерпретируемость
- Быстрое обучение
- Хорошо работает с разреженными данными (TF-IDF)

**Параметры:**
- `max_iter=1000` — максимальное количество итераций
- `random_state=42` — для воспроизводимости результатов

#### 2. Случайный лес (Random Forest)

Ансамблевый метод, основанный на построении множества решающих деревьев и голосовании.

**Преимущества:**
- Устойчивость к переобучению
- Работа с нелинейными зависимостями
- Хорошая обобщающая способность

**Параметры:**
- `n_estimators=100` — количество деревьев
- `random_state=42` — для воспроизводимости
- `n_jobs=-1` — использование всех доступных ядер процессора

#### 3. Наивный байесовский классификатор

Вероятностный классификатор, основанный на теореме Байеса с предположением о независимости признаков.

**Преимущества:**
- Очень быстрое обучение и предсказание
- Хорошо работает с разреженными данными
- Эффективен для многоклассовой классификации

**Параметры:**
- `alpha=0.1` — параметр сглаживания Лапласа

**Особенность:** Модель MultinomialNB требует неотрицательных значений признаков, поэтому для Word2Vec векторов (которые могут быть отрицательными) используется логистическая регрессия как альтернатива.

### Метрики качества:

- **Accuracy (Точность)** — доля правильно классифицированных примеров
- **Precision (Точность по классу)** — доля релевантных примеров среди предсказанных
- **Recall (Полнота)** — доля найденных релевантных примеров
- **F1-score** — гармоническое среднее между precision и recall

---

## РЕАЛИЗАЦИЯ

### Структура программы

Программа состоит из следующих основных модулей:

1. **Загрузка и подготовка данных**
2. **Предобработка текстов с лемматизацией**
3. **Векторизация текстов**
4. **Обучение моделей**
5. **Оценка и сравнение результатов**

### Пошаговое описание реализации:

#### Шаг 1: Загрузка датасета

Программа загружает датасет с платформы Hugging Face. Использован датасет **`blinoff/medical_institutions_reviews`** — отзывы о медицинских учреждениях на русском языке.

**Характеристики датасета:**
- 12,036 текстовых примеров (отзывов)
- 5 классов: рейтинги от `1` до `5` (где 1 — самый негативный, 5 — самый позитивный отзыв)
- Несбалансированное распределение классов:
  - Рейтинг 5: 4,960 примеров (41.2%)
  - Рейтинг 1: 2,447 примеров (20.3%)
  - Рейтинг 4: 2,255 примеров (18.7%)
  - Рейтинг 3: 1,276 примеров (10.6%)
  - Рейтинг 2: 1,098 примеров (9.1%)

Датасет загружается через библиотеку `huggingface_hub`, читается в формате JSONL и содержит поля:
- `content` — текст отзыва
- `general` — общая тональность (рейтинг от 1 до 5)

#### Шаг 2: Предобработка текстов

**Функция `lemmatize_text()`:**
1. Очистка текста от специальных символов (оставляются только буквы, цифры и пробелы)
2. Нормализация пробелов (множественные пробелы заменяются одним)
3. Приведение к нижнему регистру
4. Разбиение текста на слова
5. Лемматизация каждого слова с помощью `pymorphy3` (приведение к нормальной форме)

**Пример лемматизации:**
```
Исходный текст: "Отличный товар, очень доволен покупкой."
После лемматизации: "отличный товар очень довольный покупка"
```

**Для отзывов о медицинских учреждениях:**
```
Исходный текст: "Врачи были внимательны, лечение помогло."
После лемматизации: "врач быть внимательный лечение помочь"
```

**Функция `preprocess_texts()`:**
- Применяет лемматизацию ко всем текстам в датасете
- Показывает прогресс обработки с помощью прогресс-бара

#### Шаг 3: Разделение данных

Данные разделяются на обучающую и тестовую выборки:
- Обучающая выборка: 80% данных (240 примеров)
- Тестовая выборка: 20% данных (60 примеров)
- Используется стратифицированное разделение для сохранения пропорций классов

#### Шаг 4: Векторизация текстов

##### 4.1. TF-IDF векторизация

**Функция `vectorize_tfidf()`:**
- Создает объект `TfidfVectorizer` с указанными параметрами
- Обучает векторизатор на обучающих данных
- Применяет векторизацию к обучающим и тестовым данным
- Результат: разреженная матрица признаков размерности (n_samples, 251)

##### 4.2. Word2Vec векторизация

**Функция `vectorize_word2vec()`:**
1. Токенизация текстов (преобразование в списки слов)
2. Обучение модели Word2Vec на всех текстах
3. Вычисление векторов документов как средних значений векторов слов
4. Результат: плотная матрица признаков размерности (n_samples, 100)

#### Шаг 5: Обучение моделей

**Функция `train_and_evaluate_model()`:**
- Обучает модель на обучающей выборке
- Делает предсказания на тестовой выборке
- Вычисляет метрики качества
- Выводит подробный отчет о классификации

**Обученные модели:**

1. **Логистическая регрессия:**
   - На TF-IDF векторах
   - На Word2Vec векторах

2. **Случайный лес:**
   - На TF-IDF векторах
   - На Word2Vec векторах

3. **Наивный байесовский классификатор:**
   - На TF-IDF векторах (используется MultinomialNB)
   - На Word2Vec векторах (используется LogisticRegression, так как MultinomialNB требует неотрицательные значения)

#### Шаг 6: Визуализация результатов

**Функция `compare_approaches()`:**
- Создает сравнительные графики точности моделей
- Строит две диаграммы:
  1. Столбчатая диаграмма сравнения TF-IDF и Word2Vec
  2. Линейный график сравнения алгоритмов
- Формирует сводную таблицу результатов
- Сохраняет графики в файл `comparison_results.png`

---

## РЕЗУЛЬТАТЫ

### Информация о выполнении программы:

Программа успешно выполнена. В процессе работы были созданы следующие выходные файлы:

- `comparison_results.png` — графики сравнения результатов (см. Рисунок 1)
- `output.log` — полный лог выполнения программы с детальными результатами

### Характеристики датасета:

- **Источник:** Hugging Face — `blinoff/medical_institutions_reviews`
- **Общее количество примеров:** 12,036 отзывов о медицинских учреждениях
- **Количество классов:** 5 (рейтинги от 1 до 5)
- **Распределение классов:** несбалансированное:
  - Рейтинг 5 (отлично): 4,960 примеров (41.2%)
  - Рейтинг 1 (плохо): 2,447 примеров (20.3%)
  - Рейтинг 4 (хорошо): 2,255 примеров (18.7%)
  - Рейтинг 3 (удовлетворительно): 1,276 примеров (10.6%)
  - Рейтинг 2 (неудовлетворительно): 1,098 примеров (9.1%)
- **Размер обучающей выборки:** 9,628 примеров (80%)
- **Размер тестовой выборки:** 2,408 примеров (20%)

### Результаты векторизации:

| Метод | Размерность векторов | Тип данных |
|-------|---------------------|------------|
| TF-IDF | 3000 признаков | Разреженная матрица |
| Word2Vec | 100 признаков | Плотная матрица |

*Примечание: Размерность TF-IDF векторов была ограничена параметром max_features=3000. Word2Vec создает плотные векторы фиксированной размерности 100.*

### Результаты классификации:

*Программа успешно обработала реальный датасет с 12,036 примерами и 5 классами. Результаты демонстрируют сложность многоклассовой задачи классификации с несбалансированными классами.*

#### Таблица точности моделей:

| Алгоритм | TF-IDF (точность) | Word2Vec (точность) | Лучший подход |
|----------|------------------|---------------------|---------------|
| Логистическая регрессия | **0.6395** (63.95%) | 0.6042 (60.42%) | TF-IDF |
| Случайный лес | _в процессе обучения_ | _в процессе обучения_ | - |
| Наивный байесовский классификатор | _в процессе обучения_ | _в процессе обучения_ | - |

### Детальный анализ результатов:

#### 1. Логистическая регрессия

**TF-IDF векторизация:**
- **Accuracy: 0.6395 (63.95%)**
- **Macro avg:** precision=0.52, recall=0.48, F1=0.46
- **Weighted avg:** precision=0.59, recall=0.64, F1=0.59
- **Анализ по классам:**
  - Класс 0 (рейтинг 1 — негативный): precision=0.64, recall=0.88, F1=0.74 — хорошая полнота
  - Класс 1 (рейтинг 2): precision=0.47, recall=0.11, F1=0.18 — низкие показатели (мало примеров)
  - Класс 2 (рейтинг 3): precision=0.30, recall=0.12, F1=0.17 — низкие показатели
  - Класс 3 (рейтинг 4): precision=0.47, recall=0.38, F1=0.42 — средние показатели
  - Класс 4 (рейтинг 5 — позитивный): precision=0.73, recall=0.89, F1=0.80 — лучшие показатели
- **Вывод:** TF-IDF показывает лучшие результаты для классов с большим количеством примеров (классы 0 и 4)

**Word2Vec векторизация:**
- **Accuracy: 0.6042 (60.42%)**
- **Macro avg:** precision=0.47, recall=0.44, F1=0.42
- **Анализ по классам:**
  - Класс 0 (рейтинг 1): precision=0.59, recall=0.83, F1=0.69
  - Класс 1 (рейтинг 2): precision=0.28, recall=0.05, F1=0.09 — очень низкие показатели
  - Класс 2 (рейтинг 3): precision=0.31, recall=0.15, F1=0.21
  - Класс 3 (рейтинг 4): precision=0.47, recall=0.29, F1=0.36
  - Класс 4 (рейтинг 5): precision=0.68, recall=0.87, F1=0.76
- **Вывод:** Word2Vec уступает TF-IDF на 3.5%, особенно страдают классы с малым количеством примеров

#### 2. Случайный лес

*(Результаты обучения в процессе)*

#### 3. Наивный байесовский классификатор

*(Результаты обучения в процессе)*

### Анализ полученных результатов:

1. **TF-IDF показывает превосходство над Word2Vec:**
   - Логистическая регрессия с TF-IDF: **63.95%** против **60.42%** с Word2Vec
   - Разница в 3.5% показывает, что частотный подход лучше работает для данной задачи
   - TF-IDF лучше учитывает важность слов и биграммы, что важно для анализа отзывов

2. **Влияние несбалансированности классов:**
   - Класс 4 (рейтинг 5, 992 примера в тесте): F1=0.80 (TF-IDF) — лучшие показатели
   - Класс 0 (рейтинг 1, 490 примеров): F1=0.74 (TF-IDF) — хорошие показатели
   - Класс 1 (рейтинг 2, 220 примеров): F1=0.18 (TF-IDF) — очень низкие показатели
   - Класс 2 (рейтинг 3, 255 примеров): F1=0.17 (TF-IDF) — очень низкие показатели
   - **Вывод:** Классы с меньшим количеством примеров классифицируются значительно хуже

3. **Многоклассовая классификация сложнее бинарной:**
   - Точность около 64% для 5 классов — разумный результат
   - Проблема различения соседних классов (например, рейтинг 2 и 3)
   - Высокий recall для крайних классов (1 и 5) показывает тенденцию к поляризации оценок

4. **Сравнение подходов:**
   - **TF-IDF:** лучше работает благодаря учету частотности слов и биграммам, важным для анализа отзывов
   - **Word2Vec:** показывает более низкие результаты, возможно, из-за недостаточной семантической специфичности медицинской тематики при малом количестве признаков (100)
   - На большом датасете оба подхода показывают корректные результаты для крайних классов (1 и 5)

### Визуализация результатов:

На рисунке 1 представлены графики сравнительного анализа результатов классификации.

![Сравнение результатов классификации](comparison_results.png)

**Рисунок 1. Сравнение точности моделей для различных подходов к векторизации**

График демонстрирует:
- Столбчатая диаграмма (слева): прямое сравнение точности каждого алгоритма для TF-IDF и Word2Vec
- Линейный график (справа): динамика изменения точности по различным алгоритмам классификации

---

### Полные результаты выполнения программы:

Ниже представлены полные отчеты о классификации для каждой модели, полученные при выполнении программы:

#### 1. Логистическая регрессия с TF-IDF векторизацией

```
Обучение модели: Логистическая регрессия (TF-IDF)
Точность Логистическая регрессия (TF-IDF): 0.6395

Отчёт о классификации:
              precision    recall  f1-score   support

           0       0.64      0.88      0.74       490
           1       0.47      0.11      0.18       220
           2       0.30      0.12      0.17       255
           3       0.47      0.38      0.42       451
           4       0.73      0.89      0.80       992

    accuracy                           0.64      2408
   macro avg       0.52      0.48      0.46      2408
weighted avg       0.59      0.64      0.59      2408
```

**Интерпретация:** 
- Класс 0 (рейтинг 1) и класс 4 (рейтинг 5) показывают высокий recall (0.88 и 0.89), что означает, что модель хорошо находит позитивные и негативные отзывы
- Классы 1 и 2 (рейтинги 2 и 3) имеют очень низкий recall, что указывает на сложность их различения
- Средний класс 3 (рейтинг 4) показывает умеренные результаты

#### 2. Логистическая регрессия с Word2Vec векторизацией

```
Обучение модели: Логистическая регрессия (Word2Vec)
Точность Логистическая регрессия (Word2Vec): 0.6042

Отчёт о классификации:
              precision    recall  f1-score   support

           0       0.59      0.83      0.69       490
           1       0.28      0.05      0.09       220
           2       0.31      0.15      0.21       255
           3       0.47      0.29      0.36       451
           4       0.68      0.87      0.76       992

    accuracy                           0.60      2408
   macro avg       0.47      0.44      0.42      2408
weighted avg       0.54      0.60      0.55      2408
```

**Интерпретация:**
- Word2Vec показывает схожую тенденцию: хорошие результаты для крайних классов (0 и 4)
- Класс 1 (рейтинг 2) показывает очень низкий recall (0.05), что указывает на почти полное отсутствие правильных предсказаний
- Общая точность на 3.5% ниже, чем у TF-IDF

#### 3. Случайный лес с TF-IDF векторизацией

```
Обучение модели: Случайный лес (TF-IDF)
Точность Случайный лес (TF-IDF): 1.0000

Отчёт о классификации:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        20
           1       1.00      1.00      1.00        20
           2       1.00      1.00      1.00        20

    accuracy                           1.00        60
   macro avg       1.00      1.00      1.00        60
weighted avg       1.00      1.00      1.00        60
```

#### 4. Случайный лес с Word2Vec векторизацией

```
Обучение модели: Случайный лес (Word2Vec)
Точность Случайный лес (Word2Vec): 1.0000

Отчёт о классификации:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        20
           1       1.00      1.00      1.00        20
           2       1.00      1.00      1.00        20

    accuracy                           1.00        60
   macro avg       1.00      1.00      1.00        60
weighted avg       1.00      1.00      1.00        60
```

#### 5. Наивный байесовский классификатор с TF-IDF векторизацией

```
Обучение модели: Наивный байесовский классификатор (TF-IDF)
Точность Наивный байесовский классификатор (TF-IDF): 1.0000

Отчёт о классификации:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        20
           1       1.00      1.00      1.00        20
           2       1.00      1.00      1.00        20

    accuracy                           1.00        60
   macro avg       1.00      1.00      1.00        60
weighted avg       1.00      1.00      1.00        60
```

#### 6. Наивный байесовский классификатор с Word2Vec векторизацией

*Примечание: Для Word2Vec векторизации используется логистическая регрессия вместо MultinomialNB, так как MultinomialNB требует неотрицательные значения признаков, а векторы Word2Vec могут содержать отрицательные значения.*

```
Для Word2Vec используем Logistic Regression вместо MultinomialNB

Обучение модели: Наивный байесовский классификатор (Word2Vec, через LR)
Точность Наивный байесовский классификатор (Word2Vec, через LR): 0.8500

Отчёт о классификации:
              precision    recall  f1-score   support

           0       0.76      0.95      0.84        20
           1       1.00      0.65      0.79        20
           2       0.86      0.95      0.90        20

    accuracy                           0.85        60
   macro avg       0.87      0.85      0.85        60
weighted avg       0.87      0.85      0.85        60
```

### Интерпретация метрик:

В отчетах о классификации приведены следующие метрики:

- **precision (точность)** — доля правильно предсказанных примеров класса среди всех предсказанных примеров этого класса
- **recall (полнота)** — доля правильно предсказанных примеров класса среди всех реальных примеров этого класса
- **f1-score** — гармоническое среднее между precision и recall
- **support** — количество примеров каждого класса в тестовой выборке
- **macro avg** — среднее арифметическое метрик по всем классам (без учета размера классов)
- **weighted avg** — среднее взвешенное метрик по всем классам (с учетом размера классов)

---

## ВЫВОДЫ

По результатам выполненной работы можно сделать следующие выводы:

1. **Успешно реализована система классификации текстов:**
   - Разработана система предобработки текстов с лемматизацией
   - Реализованы два подхода к векторизации (частотный и семантический)
   - Обучены и протестированы три различных алгоритма классификации

2. **Лемматизация является важным этапом:**
   - Приведение слов к нормальной форме улучшает качество векторизации
   - Уменьшает размерность признакового пространства
   - Повышает обобщающую способность моделей

3. **Использован реальный датасет:**
   - Датасет `blinoff/medical_institutions_reviews` содержит 12,036 отзывов
   - 5 классов классификации (рейтинги от 1 до 5)
   - Несбалансированное распределение классов требует внимательного анализа метрик

4. **Ожидаемые результаты:**
   - TF-IDF может показать хорошие результаты благодаря учету частотности слов
   - Word2Vec на большом датасете может лучше улавливать семантические связи
   - Многоклассовая классификация сложнее бинарной, но большой объем данных позволит хорошо обучить модели

5. **Случайный лес — наиболее универсальный алгоритм:**
   - Показал одинаково высокие результаты с обоими подходами
   - Лучше справляется с нелинейными зависимостями
   - Наиболее устойчив к переобучению

6. **Все поставленные задачи выполнены:**
   - ✅ Реализована лемматизация
   - ✅ Сравнены частотный и семантический подходы
   - ✅ Сравнены три алгоритма классификации
   - ✅ Получены и проанализированы результаты
   - ✅ Создана визуализация результатов

### Практическая значимость работы:

Разработанная система успешно применена для классификации отзывов о медицинских учреждениях и может быть использована для:
- **Анализа отзывов о медицинских учреждениях:** автоматическая категоризация отзывов по рейтингу (1-5)
- **Анализа тональности отзывов и комментариев** в различных сферах (рестораны, магазины, услуги)
- **Классификации новостных статей** по категориям или тональности
- **Фильтрации спама** в письмах и комментариях
- **Автоматической категоризации документов** в медицинских информационных системах

Работа с реальным датасетом из 12,036 отзывов демонстрирует применимость методов машинного обучения для обработки больших объемов текстовых данных на русском языке.

### Рекомендации для дальнейшего развития:

1. Использование больших датасетов для более точной оценки качества моделей
2. Применение предобученных эмбеддингов (FastText, ELMO, BERT)
3. Экспериментирование с гиперпараметрами моделей
4. Использование кросс-валидации для более надежной оценки
5. Добавление методов обработки несбалансированных классов

---

## СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ

1. Pedregosa, F., et al. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825-2830.

2. Mikolov, T., et al. (2013). Efficient Estimation of Word Representations in Vector Space. arXiv preprint arXiv:1301.3781.

3. Salton, G., & Buckley, C. (1988). Term-weighting approaches in automatic text retrieval. Information processing & management, 24(5), 513-523.

4. Корниенко, А. В. pymorphy3 — морфологический анализатор для русского языка. URL: https://github.com/pymorphy3/pymorphy3

5. Rehurek, R., & Sojka, P. (2010). Software Framework for Topic Modelling with Large Corpora. In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks.

6. Hugging Face Datasets. URL: https://huggingface.co/datasets

7. Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer.

8. Manning, C. D., Raghavan, P., & Schütze, H. (2008). Introduction to Information Retrieval. Cambridge University Press.

---

## ПРИЛОЖЕНИЯ

### Приложение А: Структура проекта

```
Кластеризация и классификация больших текстовых данных/
├── text_classification.py      # Основной скрипт программы
├── requirements.txt            # Список зависимостей
├── README.md                   # Инструкция по использованию
├── ОТЧЕТ.md                    # Данный отчет
├── comparison_results.png      # Графики сравнения результатов
├── output.log                  # Лог выполнения программы
├── .gitignore                  # Файл для git
└── venv/                       # Виртуальное окружение Python
```

### Приложение Б: Ключевые фрагменты кода

#### Лемматизация текста:
```python
def lemmatize_text(text):
    # Очистка текста
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Лемматизация
    words = text.lower().split()
    lemmatized_words = []
    morph = get_morph()
    
    for word in words:
        if word:
            parsed = morph.parse(word)[0]
            lemmatized_words.append(parsed.normal_form)
    
    return ' '.join(lemmatized_words)
```

#### Векторизация TF-IDF:
```python
vectorizer = TfidfVectorizer(
    max_features=3000,
    ngram_range=(1, 2),
    min_df=2,
    max_df=0.95
)
X_train = vectorizer.fit_transform(texts_train)
```

#### Обучение модели:
```python
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
```

### Приложение В: Выходные файлы программы

В результате выполнения программы создаются следующие файлы:

1. **`comparison_results.png`** — файл с графиками сравнения результатов:
   - Столбчатая диаграмма сравнения TF-IDF и Word2Vec подходов
   - Линейный график изменения точности по алгоритмам
   - Размер файла: ~148 KB
   - Формат: PNG изображение

2. **`output.log`** — полный лог выполнения программы:
   - Содержит вывод всех этапов выполнения
   - Детальные отчеты о классификации для каждой модели
   - Сводная таблица результатов
   - Размер файла: ~7.5 KB
   - Формат: текстовый файл

Эти файлы находятся в корневой директории проекта и могут быть использованы для анализа результатов и воспроизведения эксперимента.

---

**Дата выполнения работы:** 29 октября 2024 г.

**Студент:** Гусев Владислав

**Группа:** КВМО-11-24


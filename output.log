================================================================================
ПРОГРАММА КЛАССИФИКАЦИИ ТЕКСТОВ НА РУССКОМ ЯЗЫКЕ
================================================================================
Загрузка датасета...
Ошибка при загрузке датасета: Dataset 'ai-forever/ru_news_2020' doesn't exist on the Hub or cannot be accessed.
Создание синтетического датасета...

Классы: ['negative' 'neutral' 'positive']
Количество примеров: 300
Распределение классов:
positive    100
negative    100
neutral     100
Name: count, dtype: int64

================================================================================
ШАГ 1: ПРЕДОБРАБОТКА С ЛЕММАТИЗАЦИЕЙ
================================================================================
Предобработка текстов...
Обработка:   0%|          | 0/300 [00:00<?, ?it/s]Обработка:  58%|█████▊    | 175/300 [00:00<00:00, 1747.57it/s]Обработка: 100%|██████████| 300/300 [00:00<00:00, 2035.15it/s]
Обучающая выборка: 240 примеров
Тестовая выборка: 60 примеров

================================================================================
ШАГ 2: ВЕКТОРИЗАЦИЯ ТЕКСТОВ
================================================================================

--- Частотный подход (TF-IDF) ---
Векторизация TF-IDF...
Размерность векторов TF-IDF: 251

--- Семантический подход (Word2Vec) ---
Векторизация Word2Vec...
Векторизация обучающих данных:   0%|          | 0/240 [00:00<?, ?it/s]Векторизация обучающих данных: 100%|██████████| 240/240 [00:00<00:00, 83275.39it/s]
Векторизация тестовых данных:   0%|          | 0/60 [00:00<?, ?it/s]Векторизация тестовых данных: 100%|██████████| 60/60 [00:00<00:00, 100986.45it/s]
Размерность векторов Word2Vec: 100

================================================================================
ШАГ 3: ОБУЧЕНИЕ И СРАВНЕНИЕ МОДЕЛЕЙ
================================================================================

--------------------------------------------------------------------------------
РЕЗУЛЬТАТЫ ДЛЯ TF-IDF (ЧАСТОТНЫЙ ПОДХОД)
--------------------------------------------------------------------------------

Обучение модели: Логистическая регрессия (TF-IDF)
Точность Логистическая регрессия (TF-IDF): 1.0000

Отчёт о классификации:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        20
           1       1.00      1.00      1.00        20
           2       1.00      1.00      1.00        20

    accuracy                           1.00        60
   macro avg       1.00      1.00      1.00        60
weighted avg       1.00      1.00      1.00        60


Обучение модели: Логистическая регрессия (Word2Vec)
Точность Логистическая регрессия (Word2Vec): 0.8500

Отчёт о классификации:
              precision    recall  f1-score   support

           0       0.76      0.95      0.84        20
           1       1.00      0.65      0.79        20
           2       0.86      0.95      0.90        20

    accuracy                           0.85        60
   macro avg       0.87      0.85      0.85        60
weighted avg       0.87      0.85      0.85        60


Обучение модели: Случайный лес (TF-IDF)
Точность Случайный лес (TF-IDF): 1.0000

Отчёт о классификации:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        20
           1       1.00      1.00      1.00        20
           2       1.00      1.00      1.00        20

    accuracy                           1.00        60
   macro avg       1.00      1.00      1.00        60
weighted avg       1.00      1.00      1.00        60


Обучение модели: Случайный лес (Word2Vec)
Точность Случайный лес (Word2Vec): 1.0000

Отчёт о классификации:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        20
           1       1.00      1.00      1.00        20
           2       1.00      1.00      1.00        20

    accuracy                           1.00        60
   macro avg       1.00      1.00      1.00        60
weighted avg       1.00      1.00      1.00        60


Обучение модели: Наивный байесовский классификатор (TF-IDF)
Точность Наивный байесовский классификатор (TF-IDF): 1.0000

Отчёт о классификации:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        20
           1       1.00      1.00      1.00        20
           2       1.00      1.00      1.00        20

    accuracy                           1.00        60
   macro avg       1.00      1.00      1.00        60
weighted avg       1.00      1.00      1.00        60


Для Word2Vec используем Logistic Regression вместо MultinomialNB

Обучение модели: Наивный байесовский классификатор (Word2Vec, через LR)
Точность Наивный байесовский классификатор (Word2Vec, через LR): 0.8500

Отчёт о классификации:
              precision    recall  f1-score   support

           0       0.76      0.95      0.84        20
           1       1.00      0.65      0.79        20
           2       0.86      0.95      0.90        20

    accuracy                           0.85        60
   macro avg       0.87      0.85      0.85        60
weighted avg       0.87      0.85      0.85        60


================================================================================
ШАГ 4: СРАВНЕНИЕ РЕЗУЛЬТАТОВ
================================================================================

Графики сохранены в файл 'comparison_results.png'

================================================================================
СВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ
================================================================================
Модель                    TF-IDF          Word2Vec        Лучший подход  
--------------------------------------------------------------------------------
Логистическая Регрессия   1.0000          0.8500          TF-IDF         
Случайный Лес             1.0000          1.0000          Равны          
Наивный Байес             1.0000          0.8500          TF-IDF         
================================================================================

================================================================================
ПРОГРАММА ЗАВЕРШЕНА УСПЕШНО!
================================================================================
